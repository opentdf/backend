# nonk8s
# to run remotely:
# vault login -method=okta username=pflynn
# aws-auth mgmt-developer
# export CLUSTER_NAME=k8s-mgmt
# aws eks update-kubeconfig --name $CLUSTER_NAME --region $CLUSTER_REGION
# kubens argo-events
# from .github/actions/argo-publish/entrypoint.sh
# argo submit -n argo-events ./.argo/publish/workflow.yaml -p environment="development" -p ciCommitSha=$GITHUB_SHA -p gitRepoName=etheria --wait --log
# to get last fail message:
# argo get @latest
# templateRef: cwft- located https://github.com/virtru-corp/gitops/tree/main/argocd/aws/common/us-west-2/green/argo%20k1%20copy/components/cwfts
apiVersion: argoproj.io/v1alpha1
kind: Workflow
# This workflow loops over all the Etheria components and publishes their artifacts, tagged with the current Git shortSha
metadata:
  generateName: etheria-pr-ci-
spec:
  podGC:
    # Pod GC strategy must be one of the following:
    
    # * OnPodCompletion - delete pods immediately when pod is completed (including errors/failures)
    # * OnPodSuccess - delete pods immediately when pod is successful
    # * OnWorkflowCompletion - delete pods when workflow is completed
    # * OnWorkflowSuccess - delete pods when workflow is successful
    strategy: OnWorkflowCompletion
  arguments:
    parameters:
      # This list defines what containers and charts the pipeline will publish
      # Adding new entries will publish new artifacts
      # NOTE -
      # For this pipeline to work
      #  - appName MUST == charts/<appChartFolderName>
      #  - appName MUST == containers/<appContainerFolderName>
      #
      # yes this means you have to call the same thing by the same name everywhere.
      # The one exception to this is the Dockerhub repo name, which does not have
      # to be the same as the internal service name.
      # TODO consider if this should be autogenerated based on contents of `/charts` or `/containers`
    - name: service-list
      value: |
        [
          { "appName": "tdf-key-access", "dockerHubRepoName": "opentdf/tdf-key-access", "hasChart": "true", "hasImage": "true"},
          { "appName": "tdf-entity-attribute", "dockerHubRepoName": "opentdf/tdf-entity-attribute", "hasChart": "true", "hasImage": "true" },
          { "appName": "tdf-attribute-provider", "dockerHubRepoName": "opentdf/tdf-attribute-provider", "hasChart": "true", "hasImage": "true" },
          { "appName": "tdf-identity-bootstrap", "dockerHubRepoName": "opentdf/tdf-identity-bootstrap", "hasChart": "true", "hasImage": "true" },
          { "appName": "tdf-attribute-authority", "dockerHubRepoName": "opentdf/tdf-attribute-authority", "hasChart": "true", "hasImage": "true" },
          { "appName": "tdf-entitlement", "dockerHubRepoName": "opentdf/tdf-entitlement", "hasChart": "true", "hasImage": "true" },
          { "appName": "tdf-remote-payload", "dockerHubRepoName": "opentdf/tdf-remote-payload", "hasChart": "true", "hasImage": "true" },
          { "appName": "tdf-identity", "dockerHubRepoName": "opentdf/tdf-identity", "hasChart": "false", "hasImage": "true" },
          { "appName": "etheria", "dockerHubRepoName": "", "hasChart": "true", "hasImage": "false" }
        ]
    - name: buildImage
      value: 833190184321.dkr.ecr.us-west-2.amazonaws.com/virtru-builder:1.0.16
    - name: gitRepoName
      value: etheria
    - name: branch
      value: "{{workflow.parameters.branch}}"
    - name: dockerHubRepoName
      value: "{{workflow.parameters.dockerHubRepoName}}"
    - name: dockerFileName
      value: "Dockerfile"
    - name: dockerExtraSwitches
      value: ""
    - name: gitRepoUrl
      value: "{{workflow.parameters.gitRepoUrl}}"
    - name: ciCommitSha
      value: "{{workflow.parameters.ciCommitSha}}"

  entrypoint: etheria-pipeline
  serviceAccountName: argo-events-sa
  # This template uses docker-compose to build {{inputs.appName}},
  # assuming the docker compose has an entry named {{inputs.appName}}
  # TODO we can drop docker compose here and just cd to `containers/{{appName}}`
  # But not all containers currently can build cleanly from just their dockerfile - that has to be fixed first.
  templates:
    - name: tpl-docker-compose-build-push
      inputs:
        parameters:
          - name: dockerHubRepoName
          - name: appName
          - name: imageVersionTag
        artifacts:
        - name: repo-source
          path: /src
      container:
        image: "{{workflow.parameters.buildImage}}"
        env:
          - name: DOCKER_HOST
            value: "tcp://localhost:2375"
          - name: AWS_PROFILE
            value: mgmt
        envFrom:
        - secretRef:
            name: ci-secrets
        workingDir: "/src/{{workflow.parameters.gitRepoName}}"
        command: ["/bin/sh", "-c"]
        args:
        - set -e;
          pip3 install docker-compose;
          until docker ps; do sleep 3; done;
          echo "ETHERIA_TAG={{inputs.parameters.imageVersionTag}}" >> .env;
          echo "logging into dockerhub";
          docker login -u $DOCKERHUB_USERNAME -p $DOCKERHUB_PASSWORD;
          echo "building container";
          docker-compose -f docker-compose.build.yml build python-base;
          docker-compose -f docker-compose.build.yml build {{inputs.parameters.appName}};
          docker image ls;
          echo "tagging container";
          docker tag opentdf/{{inputs.parameters.appName}}:{{inputs.parameters.imageVersionTag}} {{inputs.parameters.dockerHubRepoName}}:{{inputs.parameters.imageVersionTag}};
          echo "pushing container {{inputs.parameters.dockerHubRepoName}}:{{inputs.parameters.imageVersionTag}} to dockerhub";
          docker push {{inputs.parameters.dockerHubRepoName}}:{{inputs.parameters.imageVersionTag}};
      sidecars:
      - name: dind
        image: docker:19.03.13-dind
        env:
          - name: DOCKER_TLS_CERTDIR
            value: ""
        securityContext:
          privileged: true
        mirrorVolumeMounts: true

    # This builds a JSON object
    # tying together the revved app,
    # the Helm version we're revving to,
    # and the Docker tag we're revving to.
    # We will later take a list of these and update every chart in the repo.
    - name: tpl-compile-version-tag-data
      inputs:
        parameters:
        - name: buildImage
        - name: appName
        - name: newHelmVer
        - name: newImageTag
        - name: hasImage
        - name: shortSha
      script:
        image: "{{inputs.parameters.buildImage}}"
        command: [python3]
        source: |
          import json
          # a Python object (dict):
          tagDoc = {
            "appName": "{{inputs.parameters.appName}}",
            "newHelmVer": "{0}-rc-{1}".format({{inputs.parameters.newHelmVer}}, "{{inputs.parameters.shortSha}}"),
            "newImageTag": "{{inputs.parameters.newImageTag}}",
            "hasImage": "{{inputs.parameters.hasImage}}"
          }

          # the result is a JSON string:
          print(json.dumps(tagDoc))


    # A template that defines a sequence of steps to read a current app's
    # chart version, generate a new version containing the current shortSha,
    # and emit a JSON document joining the appname, and the proposed version
    - name: tpl-tag-helmcharts
      inputs:
        parameters:
        - name: appName
        - name: buildImage
        - name: shortSha
        - name: hasImage
        - name: imageTag
        artifacts:
        - name: repo
      steps:
        - - name: get-chart-version
            templateRef:
              name: cwft-helm
              template: get-chart-version
              clusterScope: true
            arguments:
              artifacts:
              - name: repo-source
                from: "{{inputs.artifacts.repo}}"
              parameters:
              - name: gitRepoName
                value: "{{workflow.parameters.gitRepoName}}"
              - name: chartDirectory
                value: "charts/{{inputs.parameters.appName}}"
              - name: buildImage
                value: "{{inputs.parameters.buildImage}}"
        - - name: strip-chart-version
            templateRef:
              name: cwft-helm
              template: strip-chart-version
              clusterScope: true
            arguments:
              parameters:
              - name: buildImage
                value: "{{inputs.parameters.buildImage}}"
              - name: chartVersion
                value: "{{steps.get-chart-version.outputs.result}}"
        - - name: compile-version-tag-data
            template: tpl-compile-version-tag-data
            arguments:
              parameters:
              - name: buildImage
                value: "{{inputs.parameters.buildImage}}"
              - name: appName
                value: "{{inputs.parameters.appName}}"
              - name: newHelmVer
                value: "{{steps.strip-chart-version.outputs.result}}"
              - name: shortSha
                value: "{{inputs.parameters.shortSha}}"
              - name: hasImage
                value: "{{inputs.parameters.hasImage}}"
              - name: newImageTag
                value: "{{inputs.parameters.imageTag}}"
      outputs:
        parameters:
        - name: tagData
          valueFrom:
            parameter: "{{steps.compile-version-tag-data.outputs.result}}"

    # Given a JSON document with an array of generated version tags/results, iterate through them
    # and update all the chart versions "on disk"
    - name: tpl-write-helmchart-versions
      inputs:
        artifacts:
        - name: repo-source
          path: /src
        parameters:
        - name: tagData
        - name: gitRepoName
        - name: defaultBranch
      script:
        image: 833190184321.dkr.ecr.us-west-2.amazonaws.com/kubefirst-builder:0.6
        command: [python3]
        workingDir: "/src/{{inputs.parameters.gitRepoName}}"
        source: |
          import yaml, json

          inputSet = {{inputs.parameters.tagData}}
          tagSet = []

          print('Input JSON:')
          print(json.dumps(inputSet))
          for tag in inputSet:
            tagSet.append(json.loads(tag['tagData']))

          for appTags in tagSet:
            print("Updating chart for: {0}".format(appTags['appName']))
            with open("charts/{0}/Chart.yaml".format(appTags['appName'])) as f:
                chart_yaml = yaml.load(f, Loader=yaml.FullLoader)
                chart_yaml['appVersion'] = appTags['newImageTag']
                chart_yaml['version'] = appTags['newHelmVer']

            with open("charts/{0}/Chart.yaml".format(appTags['appName']), 'w') as f:
                yaml.dump(chart_yaml, f)

            print('Updated yaml:')
            print(yaml.dump(chart_yaml))

      outputs:
        artifacts:
        - name: repo-source
          path: /src

    # Given a JSON document with an array of generated version tags/results, iterate through them
    # and update all the chart versions "on disk"
    - name: tpl-write-image-versions
      inputs:
        artifacts:
        - name: repo-source
          path: /src
        parameters:
        - name: tagData
        - name: gitRepoName
        - name: defaultBranch
      script:
        image: 833190184321.dkr.ecr.us-west-2.amazonaws.com/kubefirst-builder:0.6
        command: [python3]
        workingDir: "/src/{{inputs.parameters.gitRepoName}}"
        source: |
          import yaml, json

          inputSet = {{inputs.parameters.tagData}}
          tagSet = []

          print('Input JSON:')
          print(json.dumps(inputSet))
          for tag in inputSet:
            tagSet.append(json.loads(tag['tagData']))

          for appTags in tagSet:
            if appTags['hasImage'] == 'true':
              print("Updating chart container tag for: {0}".format(appTags['appName']))
              with open("charts/{0}/values.yaml".format(appTags['appName'])) as f:
                  values_yaml = yaml.load(f, Loader=yaml.FullLoader)
                  oldImageTagSansVersion = values_yaml['image']['name'].split(':')[0]
                  values_yaml['image']['name'] = "{0}:{1}".format(oldImageTagSansVersion, appTags['newImageTag'])

              with open("charts/{0}/values.yaml".format(appTags['appName']), 'w') as f:
                  yaml.dump(values_yaml, f)

              print('Updated values yaml:')
              print(yaml.dump(values_yaml))
            else:
              print("Skipping chart container tag update for: {0}, no tag supplied".format(appTags['appName']))

      outputs:
        artifacts:
        - name: repo-source
          path: /src

    # Given a JSON document with an array of generated version tags/results, iterate through them
    # and update all subchart references in the Etheria chart.
    - name: tpl-update-etheria-subchart-refs
      inputs:
        artifacts:
        - name: repo-source
          path: /src
        parameters:
        - name: tagData
        - name: gitRepoName
        - name: defaultBranch
        - name: etheriaChartFolder
          value: "etheria"
      script:
        image: 833190184321.dkr.ecr.us-west-2.amazonaws.com/kubefirst-builder:0.6
        command: [python3]
        workingDir: "/src/{{inputs.parameters.gitRepoName}}"
        source: |
          import yaml, json

          inputSet = {{inputs.parameters.tagData}}
          tagSet = []

          print('Input JSON:')
          print(json.dumps(inputSet))
          for tag in inputSet:
            tagSet.append(json.loads(tag['tagData']))


          with open("charts/{0}/Chart.yaml".format("{{inputs.parameters.etheriaChartFolder}}")) as etheriaChart:
              ethChartYaml = yaml.load(etheriaChart, Loader=yaml.FullLoader)
              for subrefs in ethChartYaml['dependencies']:
                for appTags in tagSet:
                  if subrefs['repository'].endswith(appTags['appName']):
                    subrefs['version'] = appTags['newHelmVer']


          with open("charts/{0}/Chart.yaml".format("{{inputs.parameters.etheriaChartFolder}}"), 'w') as etheriaChart:
              yaml.dump(ethChartYaml, etheriaChart)

          print('Updated Etheria Chart.yaml:')
          print(yaml.dump(ethChartYaml))

      outputs:
        artifacts:
        - name: repo-source
          path: /src

    # A lightly modified version of the shared CWFT that just uses the version in Chart.yaml as-is
    # instead of expecting an override
    # TODO extend shared CWFT to support this
    - name: tpl-helm-push-it
      inputs:
        artifacts:
        - name: repo-source
          path: /src
        parameters:
        - name: buildImage
        - name: gitRepoName
        - name: chartDirectory
      # pushes the helm chart to chart museum
      script:
        image: "{{inputs.parameters.buildImage}}"
        command: [bash]
        workingDir: /src
        envFrom:
        - secretRef:
            name: ci-secrets
        - secretRef:
            name: chartmuseum-secrets
        - configMapRef:
            name: ci-cm
        source: |
          set -e
          echo "pushing {{inputs.parameters.chartDirectory}} chart to virtru chartmuseum"
          helm repo add virtru https://charts.production.virtru.com
          helm push  ./{{inputs.parameters.gitRepoName}}/{{inputs.parameters.chartDirectory}} virtru
      outputs:
        artifacts:
        - name: repo-source
          path: /src

    #----------------------------------------
    # END templates, begin actual pipeline/entrypoint
    # ---------------------------------------
    - name: etheria-pipeline
      inputs:
        parameters:
          - name: service-list # The list of apps, as defined in the workflow above
      # Suggest we stick to a DAG - Etheria is complex.
      dag:
        tasks:
        #A task to clone the repo, and emit the result as a tarball for consumption by downstream tasks.
        - name: git-checkout-with-gitops
          templateRef:
            name: cwft-git-v2
            template: git-checkout-with-gitops
            clusterScope: true
          arguments:
            parameters:
            - name: appDir
              value: /src/etheria
            - name: branch
              value: "{{workflow.parameters.branch}}"
            - name: gitRepoUrl
              value: "{{workflow.parameters.gitRepoUrl}}"

        #Get a git shortref sha from the full commit sha (used for tagging artifacts)
        - name: get-short-sha
          dependencies: [git-checkout-with-gitops]
          templateRef:
            name: cwft-ci
            template: get-short-sha
            clusterScope: true
          arguments:
            artifacts:
            - name: repo-source
              from: "{{tasks.git-checkout-with-gitops.outputs.artifacts.repo-source}}"
            parameters:
            - name: gitRepoName
              value: "{{workflow.parameters.gitRepoName}}"
            - name: buildImage
              value: "{{workflow.parameters.buildImage}}"

        # For every app in {{inputs.parameters.service-list}},
        # build the base image(s), build the app image, tag it with the git SHA, and push it.
        - name: docker-compose-build-push
          dependencies: [git-checkout-with-gitops]
          withParam: "{{inputs.parameters.service-list}}"      # parameter specifies the list to iterate over
          when: "{{item.hasImage}} == true" #Not all apps have associated containers (e.g. Etheria master chart)
          template: tpl-docker-compose-build-push
          arguments:
            artifacts:
            - name: repo-source
              from: "{{tasks.git-checkout-with-gitops.outputs.artifacts.repo-source}}"
            parameters:
            - name: dockerHubRepoName
              value: "{{item.dockerHubRepoName}}"
            - name: appName
              value: "{{item.appName}}"
            - name: imageVersionTag
              value: "{{workflow.parameters.ciCommitSha}}"

        # For every app in {{inputs.parameters.service-list}},
        # fetch that app's current chart version, strip it, and build a new version.
        # All the versions and their corresponding apps will be collated into a JSON result array
        - name: build-all-helmchart-versions
          template: tpl-tag-helmcharts
          dependencies: [git-checkout-with-gitops, get-short-sha]
          withParam: "{{inputs.parameters.service-list}}"      # parameter specifies the list to iterate over
          when: "{{item.hasChart}} == true" #Not all apps have associated Helm charts.
          arguments:
            parameters:
            - name: buildImage
              value: "{{workflow.parameters.buildImage}}"
            - name: appName
              value: "{{item.appName}}"
            - name: shortSha
              value: "{{tasks.get-short-sha.outputs.result}}"
            - name: imageTag
              value: "{{workflow.parameters.ciCommitSha}}"
            - name: hasImage
              value: "{{item.hasImage}}"
            artifacts:
            - name: repo
              from: "{{tasks.git-checkout-with-gitops.outputs.artifacts.repo-source}}"

        # For all the apps/chart versions defined in the previous task's output JSON result array
        # go and update each chart's values.yaml for each app with the right image tag (the git SHA, etc)
        # TODO there might be a cleaner way to "fan in" here than compiling a JSON doc from the previous "fan-out" resultset,
        # but this works for now
        - name: set-all-imagetags-in-charts
          template: tpl-write-image-versions
          dependencies: [build-all-helmchart-versions]
          arguments:
            parameters:
            - name: tagData
              value: "{{tasks.build-all-helmchart-versions.outputs.parameters}}"
            - name: gitRepoName
              value: "{{workflow.parameters.gitRepoName}}"
            - name: defaultBranch
              value: "{{workflow.parameters.branch}}"
            artifacts:
            - name: repo-source
              from: "{{tasks.git-checkout-with-gitops.outputs.artifacts.repo-source}}"

        # For all the apps/chart versions defined in the previous task's output JSON result array
        # go and update each chart for each app with each version "on disk", and export the modified
        # repo as a tarball
        # TODO there might be a cleaner way to "fan in" here than compiling a JSON doc from the previous "fan-out" resultset,
        # but this works for now
        - name: set-all-helmchart-versions
          template: tpl-write-helmchart-versions
          dependencies: [set-all-imagetags-in-charts]
          arguments:
            parameters:
            - name: tagData
              value: "{{tasks.build-all-helmchart-versions.outputs.parameters}}"
            - name: gitRepoName
              value: "{{workflow.parameters.gitRepoName}}"
            - name: defaultBranch
              value: "{{workflow.parameters.branch}}"
            - name: githubOrg
              value: "virtru-corp"
            - name: githubSecretName
              value: "virtru-cloudnative-secrets"
            artifacts:
            - name: repo-source
              from: "{{tasks.set-all-imagetags-in-charts.outputs.artifacts.repo-source}}"

        # This is a special task that additionally updates the subchart references in the
        # top-level `etheria` chart, after updating each subchart in the previous step.
        - name: set-etheria-subchart-versions
          template: tpl-update-etheria-subchart-refs
          dependencies: [set-all-helmchart-versions]
          arguments:
            parameters:
            - name: tagData
              value: "{{tasks.build-all-helmchart-versions.outputs.parameters}}"
            - name: gitRepoName
              value: "{{workflow.parameters.gitRepoName}}"
            - name: defaultBranch
              value: "{{workflow.parameters.branch}}"
            artifacts:
            - name: repo-source
              from: "{{tasks.set-all-helmchart-versions.outputs.artifacts.repo-source}}"

        # Given the repo tarball from the previous step with the "in-place" modified helmcharts, loop through each
        # app in our original {{inputs.parameters.service-list}} and publish each chart
        - name: helm-push
          dependencies: [set-etheria-subchart-versions, set-all-imagetags-in-charts, set-all-helmchart-versions]
          withParam: "{{inputs.parameters.service-list}}"      # parameter specifies the list to iterate over
          when: "{{item.hasChart}} == true" #Not all apps have associated Helm charts.
          template: tpl-helm-push-it
          arguments:
            artifacts:
            - name: repo-source
              from: "{{tasks.set-etheria-subchart-versions.outputs.artifacts.repo-source}}"
            parameters:
            - name: buildImage
              value: "{{workflow.parameters.buildImage}}"
            - name: gitRepoName
              value: "{{workflow.parameters.gitRepoName}}"
            - name: chartDirectory
              value: charts/{{item.appName}}
